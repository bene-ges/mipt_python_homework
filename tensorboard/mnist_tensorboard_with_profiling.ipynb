{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced8b991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tb-nightly\n",
      "  Downloading tb_nightly-2.8.0a20211215-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/aleksandraa/miniconda3/envs/dl/lib/python3.9/site-packages (from tb-nightly) (58.0.4)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/aleksandraa/miniconda3/envs/dl/lib/python3.9/site-packages (from tb-nightly) (0.37.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.42.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/aleksandraa/miniconda3/envs/dl/lib/python3.9/site-packages (from tb-nightly) (1.21.2)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.3.3-py2.py3-none-any.whl (155 kB)\n",
      "Collecting protobuf>=3.6.0\n",
      "  Using cached protobuf-3.19.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: six in /home/aleksandraa/miniconda3/envs/dl/lib/python3.9/site-packages (from absl-py>=0.4->tb-nightly) (1.16.0)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/aleksandraa/miniconda3/envs/dl/lib/python3.9/site-packages (from markdown>=2.6.8->tb-nightly) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/aleksandraa/miniconda3/envs/dl/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly) (3.6.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aleksandraa/miniconda3/envs/dl/lib/python3.9/site-packages (from requests<3,>=2.21.0->tb-nightly) (2021.10.8)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.9-py3-none-any.whl (39 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tb-nightly\n",
      "Successfully installed absl-py-1.0.0 cachetools-4.2.4 charset-normalizer-2.0.9 google-auth-2.3.3 google-auth-oauthlib-0.4.6 grpcio-1.42.0 idna-3.3 markdown-3.3.6 oauthlib-3.1.1 protobuf-3.19.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.26.0 requests-oauthlib-1.3.0 rsa-4.8 tb-nightly-2.8.0a20211215 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 urllib3-1.26.7 werkzeug-2.0.2\n"
     ]
    }
   ],
   "source": [
    "! pip install tb-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "beb25719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[K     |████████████████████████████████| 292 kB 12.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /home/aleksandraa/miniconda3/envs/dl/lib/python3.9/site-packages (from seaborn) (1.7.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/aleksandraa/miniconda3/envs/dl/lib/python3.9/site-packages (from seaborn) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/aleksandraa/miniconda3/envs/dl/lib/python3.9/site-packages (from seaborn) (1.21.2)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/aleksandraa/miniconda3/envs/dl/lib/python3.9/site-packages (from seaborn) (1.3.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/aleksandraa/miniconda3/envs/dl/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/aleksandraa/miniconda3/envs/dl/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/aleksandraa/miniconda3/envs/dl/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (3.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/aleksandraa/miniconda3/envs/dl/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/aleksandraa/miniconda3/envs/dl/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/aleksandraa/miniconda3/envs/dl/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/aleksandraa/miniconda3/envs/dl/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (4.25.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/aleksandraa/miniconda3/envs/dl/lib/python3.9/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/aleksandraa/miniconda3/envs/dl/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d843ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pdb\n",
    "import seaborn as sns\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfa1eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels = 3, num_classes = 10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(16*7*7, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb982db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device= cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device=\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f1145f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "# При подборе гиперпараметров в первой части задания лучшие результаты были при (bs=2, lr=0.001) и (bs=64, lr=0.01)\n",
    "# Я выбираю второй вариант, так как при большем батче быстрее учится\n",
    "\n",
    "learning_rate = 0.01\n",
    "in_channels = 1\n",
    "num_classes  =10\n",
    "batch_size = 64\n",
    "num_epochs = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b544142f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f0875c84f5495abb72880905b15d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19d40693957436ca169624ecfcc7ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6350c05a7c7c4d548675951da115b3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09224df0254454fbefd0e64a2452fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.MNIST(root='dataset/', train=True, \n",
    "                              transform=transforms.ToTensor(), download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "75909b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "  \"\"\"\n",
    "  Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "  Args:\n",
    "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "    class_names (array, shape = [n]): String names of the integer classes\n",
    "  \"\"\"\n",
    "  figure = plt.figure(figsize=(8, 8))\n",
    "  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "  plt.title(\"Confusion matrix\")\n",
    "  plt.colorbar()\n",
    "  tick_marks = np.arange(len(class_names))\n",
    "  plt.xticks(tick_marks, class_names, rotation=45)\n",
    "  plt.yticks(tick_marks, class_names)\n",
    "\n",
    "  # Compute the labels from the normalized confusion matrix.\n",
    "  labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "  # Use white text if squares are dark; otherwise black.\n",
    "  threshold = cm.max() / 2.\n",
    "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "    plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.ylabel('True label')\n",
    "  plt.xlabel('Predicted label')\n",
    "  return figure\n",
    "\n",
    "def image_grid(class_names, train_images, train_labels, predictions):\n",
    "  \"\"\"Return a 5x5 grid of the MNIST images as a matplotlib figure.\"\"\"\n",
    "  # Create a figure to contain the plot.\n",
    "  figure = plt.figure(figsize=(12,12))\n",
    "  for i in range(25):\n",
    "    # Start next subplot.\n",
    "    plt.subplot(5, 5, i + 1, title=f\"g={class_names[train_labels[i]]}/p={class_names[predictions[i]]}\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i].squeeze(), cmap=plt.cm.binary)\n",
    "\n",
    "  return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7bffb86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss in this epoch was 0.17834300518299995\n",
      "Mean loss in this epoch was 0.08106147263696524\n",
      "Mean loss in this epoch was 0.06987114868486481\n"
     ]
    }
   ],
   "source": [
    "model = CNN(in_channels=in_channels, num_classes=num_classes)\n",
    "model.to(device)\n",
    "model.train()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0)\n",
    "writer = SummaryWriter(f'runs/MNIST/MiniBatchSize {batch_size} LR {learning_rate}')\n",
    "\n",
    "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "step = 0\n",
    "with torch.profiler.profile(\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./runs/prof'),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True\n",
    ") as prof:\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "\n",
    "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "\n",
    "            #forward\n",
    "            scores = model(data)\n",
    "            loss = criterion(scores, targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            #backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate 'running' training accuracy\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct = (predictions == targets).sum()\n",
    "            running_train_acc = float(num_correct) / float(data.shape[0])\n",
    "            accuracies.append(running_train_acc)\n",
    "\n",
    "            writer.add_scalar('Training loss', loss, global_step = step)\n",
    "            writer.add_scalar('Training accuracy', running_train_acc, global_step=step)\n",
    "            step += 1\n",
    "            prof.step()  # Need to call this at the end of each step to notify profiler of steps' boundary.\n",
    "\n",
    "        print(f'Mean loss in this epoch was {sum(losses)/len(losses)}')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa9975e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be555c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
